{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Mohan Sai Aravind Kumar\n",
    "### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   # importing re module\n",
    "import string # importing string module \n",
    "import json   # importing json module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unitcodes\n",
    "\n",
    "### Methodology\n",
    "#### Here in this task we use the regular expression to extract the unitcodes from the textfile and after extracting the the unitcodes from the text file we append those unit codes to the list named unitcodes and if there is no unitcode found we append the value of NA to the list, in the same pattern we do for the Synopsis, Prerequisities, Outputs, Prohibitions, Requirements, Chief Examiner and Unit Titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = open('30001781(1).txt','r') #reads the file\n",
    "new_file = new.read()\n",
    "unitcodes = []\n",
    "text1 = '<div class=\"content-inner__main\">'\n",
    "for line in new_file.split(text1):\n",
    "    pattern = re.compile(r'<span class=\"unitcode\">([A-Z]{3,4}[0-9]{4})</span>') #re to extract unitcodes\n",
    "    found = re.search(pattern,line)\n",
    "    if found:\n",
    "        unitcodes.append(found.group(1))\n",
    "    else:\n",
    "        unitcodes.append('NA')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopsis = [] #synopsis list\n",
    "for exp in new_file.split(text1):\n",
    "    found1 = re.search(r'Synopsis</h2>(.*?)</div>',exp,re.DOTALL) #re for synopsis \n",
    "    if found1:\n",
    "        synopsis.append(found1.group(1))\n",
    "    else:\n",
    "        synopsis.append('NA')\n",
    "\n",
    "cleaned_synopsis = []\n",
    "for items in synopsis:\n",
    "    items = items.strip().replace('\\n','')\n",
    "    match = re.sub(r'<[\\w/]*>+','',items)\n",
    "    if match:\n",
    "        cleaned_synopsis.append(match)\n",
    "    else:\n",
    "        cleaned_synopsis.append('NA')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [] #outputs list\n",
    "for value in new_file.split(text1):\n",
    "    found2 = re.search(r'<h2 class=\"hbk-heading\">Outcomes</h2>(.*?)</div>',value,re.DOTALL) #re for outputs\n",
    "    if found2:\n",
    "        outputs.append(found2.group(1))\n",
    "    else:\n",
    "        outputs.append('NA')\n",
    "#print(outputs)\n",
    "\n",
    "cleaned_outputs1 = []\n",
    "cleaned_outputs2 = []\n",
    "cleaned_outputs = []\n",
    "for items in outputs:\n",
    "    #items = items.strip().replace('\\n','')\n",
    "    match = re.sub(r'\\n<[^>]+>\\n','',items)\n",
    "    if match:\n",
    "        cleaned_outputs1.append(match)\n",
    "    else:\n",
    "        cleaned_outputs1.append('NA')\n",
    "for item1 in cleaned_outputs1:\n",
    "    match1=re.sub(r'<[^>]+>','',item1)\n",
    "    if match1:\n",
    "        cleaned_outputs2.append(match1)\n",
    "    else:\n",
    "        cleaned_outputs2.append('NA')\n",
    "for item in cleaned_outputs2:\n",
    "    item=item.split('\\n')\n",
    "    cleaned_outputs.append(item)\n",
    "        \n",
    "\n",
    "#print(cleaned_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n"
     ]
    }
   ],
   "source": [
    "prereq = []\n",
    "for pre in new_file.split(text1):\n",
    "    found4 = re.search(r'<p class=\"hbk-preamble-heading\">Prerequisites</p>(.*?)</p>',pre,re.DOTALL) #re for pre-requisities\n",
    "    if found4:\n",
    "        prereq.append(found4.group(1))\n",
    "    else:\n",
    "        prereq.append('NA')\n",
    "\n",
    "print(len(prereq))\n",
    "cleaned_pre = []\n",
    "for cleaned in prereq:\n",
    "    if cleaned == 'NA':\n",
    "        cleaned_pre.append('NA')\n",
    "    else:\n",
    "        match3 = set((re.findall(r'(?:[A-Z]{3}[0-9]{4})',cleaned,re.DOTALL)))\n",
    "        if len(match3) !=  0:\n",
    "            cleaned_pre.append(list(match3))\n",
    "        else:\n",
    "            cleaned_pre.append('NA')\n",
    "\n",
    "#print(cleaned_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Co-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreq = [] #corequisitie list\n",
    "for co in new_file.split(text1):\n",
    "    found5 = re.search(r'<p class=\"hbk-preamble-heading\">Co-requisites</p>(.*?)</p>',co,re.DOTALL) #re for corequisities\n",
    "    if found5:\n",
    "        coreq.append(found5.group(1))\n",
    "    else:\n",
    "        coreq.append('NA')\n",
    "#print(coreq)\n",
    "cleaned_coreq = []\n",
    "for clean in coreq:\n",
    "    if clean == 'NA':\n",
    "        cleaned_coreq.append('NA')\n",
    "    else:\n",
    "        match4 = set((re.findall(r'(?:[A-Z]{3}[0-9]{4})',clean,re.DOTALL)))\n",
    "        if len(match4) != 0:\n",
    "            cleaned_coreq.append(list(match4))\n",
    "        else:\n",
    "            cleaned_coreq.append('NA')\n",
    "            \n",
    "#print(cleaned_coreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Final Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_coq=[]\n",
    "for i,j in zip(cleaned_pre,cleaned_coreq):\n",
    "    if i=='NA' and j=='NA':\n",
    "        pre_coq.append('NA')\n",
    "    else:\n",
    "        if i=='NA':\n",
    "            pre_coq.append(j)\n",
    "        elif j =='NA':\n",
    "            pre_coq.append(i)\n",
    "        else:\n",
    "            pre_coq.append(i+j)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prohibitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = [] \n",
    "for lines in new_file.split(text1):\n",
    "    found6 = re.search(r'<p class=\"hbk-preamble-heading\">Prohibitions</p>(.*?)</div>',lines,re.DOTALL) #re for prohibitions\n",
    "    if found6:\n",
    "        pro.append(found6.group(1))\n",
    "    else:\n",
    "        pro.append('NA')\n",
    "#print(pro)\n",
    "\n",
    "cleaned_prob = [] #cleaned prohibitions list\n",
    "for item in pro:\n",
    "    if item == 'NA':\n",
    "        cleaned_prob.append('NA')\n",
    "    else:\n",
    "        match5=set((re.findall(r'(?:[A-Z]{3}[0-9]{4})',item,re.DOTALL)))\n",
    "        #print(match5)\n",
    "        if len(match5) != 0:\n",
    "            cleaned_prob.append(list(match5))\n",
    "        else:\n",
    "            cleaned_prob.append('NA')\n",
    "#print(cleaned_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Req = []\n",
    "for items in new_file.split(text1):\n",
    "    found7 = re.search(r'<h2 class=\"hbk-heading\">Assessment</h2>(.*?)</div>',items,re.DOTALL) #re for requirements\n",
    "    if found7:\n",
    "        Req.append(found7.group(1))\n",
    "    else:\n",
    "        Req.append('NA')\n",
    "        \n",
    "cleaned_req = []      #cleaned requirements list\n",
    "for item in Req:\n",
    "    item = item.strip().replace('\\n','')\n",
    "    match = re.sub(r'<.*?>','',item)\n",
    "    if match:\n",
    "        cleaned_req.append(match)\n",
    "    else:\n",
    "        cleaned_req.append('NA')\n",
    "    \n",
    "#cleaned_req"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chief Examiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "chief_examiner = []\n",
    "for chunks in new_file.split(text1):\n",
    "    match = re.search(r'<p class=\"hbk-highlight-heading\">Chief examiner\\(s\\)</p>(.*?)</p>',chunks,re.DOTALL) #re for chief examiner\n",
    "    if match:\n",
    "        chief_examiner.append(match.group(1))\n",
    "    else:\n",
    "        chief_examiner.append('TBA')\n",
    "\n",
    "#print(chief_examiner)\n",
    "cleaned_chiefExaminer = [] #cleaned chief examiner list\n",
    "for item in chief_examiner:\n",
    "    item = item.strip().replace('\\n','')\n",
    "    match1 = re.findall(r'>([\\w\\s-]+)<',item,re.DOTALL)\n",
    "    if match1:\n",
    "        cleaned_chiefExaminer.append(match1)\n",
    "    else:\n",
    "        cleaned_chiefExaminer.append('TBA')\n",
    "        \n",
    "#cleaned_chiefExaminer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Unit Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_title = [] #final cleaned title for lists\n",
    "for items in new_file.split(text1):\n",
    "    match = re.search(r'</span>( - )(.*?)<span class=\"hbk-archive-only\">',items) #re for unit titles\n",
    "    if match:\n",
    "        cleaned_title.append(match.group(2))\n",
    "    else:\n",
    "        cleaned_title.append('NA')\n",
    "\n",
    "#len(cleaned_title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dict = {'Unitcodes':[],\n",
    "         'Titles':[],\n",
    "         'Pre requisites':[],\n",
    "         'Prohibitions':[],\n",
    "         'Synopsis':[],\n",
    "         'Outcomes':[],\n",
    "         'Requirements':[],\n",
    "         'Chief Examiner':[]}\n",
    "for i in range(1,401):\n",
    "    unit_dict['Unitcodes'].append(unitcodes[i])\n",
    "    unit_dict['Titles'].append(cleaned_title[i])\n",
    "    unit_dict['Synopsis'].append(cleaned_synopsis[i])\n",
    "    unit_dict['Pre requisites'].append(pre_coq[i])\n",
    "    unit_dict['Prohibitions'].append(cleaned_prob[i])\n",
    "    unit_dict['Outcomes'].append(cleaned_outputs[i])\n",
    "    unit_dict['Requirements'].append(cleaned_req[i])\n",
    "    unit_dict['Chief Examiner'].append(cleaned_chiefExaminer[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we create the XML and JSON files and we append all the data which we have extracted above we append all those data her in the XML and JASON respectively, so that we get all the extracted data in the '.xml' and '.json' formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XML FILE\n",
    "xml_output = open('30001781.xml','w+') #creating the XML file\n",
    "xml_output.write('<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\\n')\n",
    "xml_output.write('<units>\\n')\n",
    "\n",
    "for x in range(0,400): #this for loop works for the range of X from 0-400\n",
    "    \n",
    "    xml_output.write('<unit id=\\'%s\\'>\\n'% unit_dict['Unitcodes'][x])\n",
    "    xml_output.write('<title> %s '% unit_dict['Titles'][x])\n",
    "    xml_output.write('</title>\\n')\n",
    "    xml_output.write('<synopsis> %s '% unit_dict['Synopsis'][x])\n",
    "    xml_output.write('</synopsis>\\n')\n",
    "    if unit_dict['Pre requisites'][x] =='NA':\n",
    "        xml_output.write('<pre_requistics> NA </pre_requistics>\\n')\n",
    "    else:\n",
    "        xml_output.write('<pre_requistics>')\n",
    "        if len(unit_dict['Pre requisites'][x]) == 1:\n",
    "            xml_output.write('<pre_requistic> %s '% unit_dict['Pre requisites'][x][0])\n",
    "            xml_output.write('</pre_requistic>\\n')\n",
    "            xml_output.write('<pre_requistics>\\n')\n",
    "        else:\n",
    "            for value in range(len(unit_dict['Pre requisites'][x])):\n",
    "                xml_output.write('<pre_requistic> %s '% unit_dict['Pre requisites'][x][value])\n",
    "                xml_output.write('</pre_requistic>\\n')\n",
    "            xml_output.write('</pre_requistics>\\n')\n",
    "    if unit_dict['Prohibitions'][x] =='NA':\n",
    "        xml_output.write('<prohibisions> NA </prohibisions>\\n')\n",
    "    else:\n",
    "        xml_output.write('<prohibisions>\\n')\n",
    "        if len(unit_dict['Prohibitions'][x]) == 1:\n",
    "            xml_output.write('<prohibition> %s '% unit_dict['Prohibitions'][x][0])\n",
    "            xml_output.write('</prohibition>\\n')\n",
    "            xml_output.write('<prohibisions>\\n')\n",
    "        else:\n",
    "            for value in range(len(unit_dict['Prohibitions'][x])):\n",
    "                xml_output.write('<prohibition> %s '% unit_dict['Prohibitions'][x][value])\n",
    "                xml_output.write('</prohibition>\\n')\n",
    "            xml_output.write('</prohibisions>\\n')\n",
    "    xml_output.write('<requirements>\\n')\n",
    "    xml_output.write('<requirement> %s '% unit_dict['Requirements'][x])\n",
    "    xml_output.write('</requirement>\\n')\n",
    "    xml_output.write('</requirements>\\n')\n",
    "    if unit_dict['Outcomes'][x] =='NA':\n",
    "        xml_output.write('<outcomes> NA </outcomes>\\n')\n",
    "    else:\n",
    "        xml_output.write('<outcomes>\\n')\n",
    "        for value1 in range(len(unit_dict['Outcomes'][x])):\n",
    "            xml_output.write('<outcome> %s '% unit_dict['Outcomes'][x][value1]) \n",
    "            xml_output.write('</outcome>\\n')\n",
    "        xml_output.write('</outcomes>\\n')\n",
    "        \n",
    "    if unit_dict['Chief Examiner'][x] =='NA':\n",
    "        xml_output.write('<chief_examiners> NA </chief_examiners>\\n')\n",
    "    else:\n",
    "        xml_output.write('<chief_examiners>\\n')\n",
    "        if len(unit_dict['Chief Examiner'][x]) == 1:\n",
    "            xml_output.write('<chief_examiner> %s '% unit_dict['Chief Examiner'][x][0])\n",
    "            xml_output.write('</chief_examiner>\\n')\n",
    "            xml_output.write('<chief_examiners>\\n')\n",
    "        else:\n",
    "            for value in range(len(unit_dict['Chief Examiner'][x])):\n",
    "                xml_output.write('<chief_examiner> %s '% unit_dict['Chief Examiner'][x][value])\n",
    "                xml_output.write('</chief_examiner>\\n')\n",
    "            xml_output.write('</chief_examiners>\\n')\n",
    "    xml_output.write('</unit>\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON FILE\n",
    "json_file = open('30001781.json','w+')   #creating the json file\n",
    "actual_dict={}\n",
    "final_dict={'unit':[] }\n",
    "for i in range(1,401): #This for loop for i works for the range in between 0-401\n",
    "    unit_dictionary ={} \n",
    "    unit_dictionary['@id'] = unitcodes[i]\n",
    "    unit_dictionary['title'] = cleaned_title[i]\n",
    "    unit_dictionary['synopsis'] = cleaned_synopsis[i]\n",
    "    if len(pre_coq[i]) ==1:\n",
    "        unit_dictionary['pre requisites'] = pre_coq[i][0]\n",
    "    else:\n",
    "        sub_dictionary={}\n",
    "        sub_dictionary['pre_requistic'] = pre_coq[i]\n",
    "        unit_dictionary['pre requisites'] =sub_dictionary\n",
    "    unit_dictionary['prohibitions'] = cleaned_prob[i]\n",
    "    if len(cleaned_req[i]) ==1:\n",
    "        unit_dictionary['requirements'] = cleaned_req[i][0]\n",
    "    else:\n",
    "        sub_dictionary={}\n",
    "        sub_dictionary['requirement'] = cleaned_req[i]\n",
    "        unit_dictionary['requirements'] = sub_dictionary\n",
    "    if len(cleaned_outputs[i]) == 1:\n",
    "        unit_dictionary['outcomes'] =cleaned_outputs[i][0]\n",
    "    else:\n",
    "        sub_dictionary={}\n",
    "        sub_dictionary['outcome'] = cleaned_outputs[i]\n",
    "        unit_dictionary['outcomes']=sub_dictionary\n",
    "    if len(cleaned_chiefExaminer[i])==1:\n",
    "        unit_dictionary['chief_examiners'] = cleaned_chiefExaminer[i][0]\n",
    "    else:\n",
    "        sub_dictionary={}\n",
    "        sub_dictionary['chief_examiner'] = cleaned_chiefExaminer[i]\n",
    "        unit_dictionary['chief_examiners'] = sub_dictionary\n",
    "    final_dict['unit'].append(unit_dictionary)\n",
    "\n",
    "actual_dict['units']={}\n",
    "actual_dict['units']=(final_dict)\n",
    "json.dump(actual_dict,json_file,indent=8)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
